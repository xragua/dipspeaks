{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adba9fc7-eb3e-4098-b320-790e52469b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## dipspeaks.dipspeaks_detection.analysis.clump_candidates\n",
      "\n",
      "Identify clumped dips between high- and low-energy features based on overlap and relative prominence.\n",
      "\n",
      "This function finds dip pairs from two energy bands (`high_dips` and `low_dips`) that overlap\n",
      "by at least `overlap_threshold` in both directions and where the low-energy dip has greater\n",
      "relative prominence than the high-energy dip. Optionally, it can display diagnostic histograms\n",
      "of dip times overlaid with the light curve.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "high_dips : pandas.DataFrame\n",
      "    DataFrame of high-energy dip features. Must contain columns:\n",
      "    - `ti`, `te`: start and end times of each dip\n",
      "    - `relprominence`: relative prominence of each dip\n",
      "    - `t`: representative time of the dip (for plotting)\n",
      "low_dips : pandas.DataFrame\n",
      "    DataFrame of low-energy dip features with the same columns as `high_dips`.\n",
      "lc : pandas.DataFrame\n",
      "    Light curve DataFrame used for context in plotting. Must contain:\n",
      "    - `t`: time array\n",
      "    - `c`: count (flux) array\n",
      "overlap_threshold : float, default=0.75\n",
      "    Minimum fractional overlap (in both high→low and low→high) required to consider two dips overlapping.\n",
      "bin_number : int, default=100\n",
      "    Number of bins to use when plotting histograms of dip times.\n",
      "show_plot : bool, default=False\n",
      "    If True, display histograms of dip times for both energy bands, overlaid with the scaled light curve.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "high_clump : pandas.DataFrame\n",
      "    Subset of `high_dips` that meet the clump criteria.\n",
      "low_clump : pandas.DataFrame\n",
      "    Corresponding subset of `low_dips` that pair with `high_clump`. \n",
      "\n",
      "## dipspeaks.dipspeaks_detection.analysis.filter_dip_peak\n",
      "\n",
      "Filter detected dips/peaks by reconstruction‑error percentile and z‑score,\n",
      "optionally plot them, and estimate their “real” probability.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "dataset : pd.DataFrame\n",
      "    Detected features on the real light curve. Must contain columns:\n",
      "    - `error_percentile` (float): percentile ranking of the reconstruction error.\n",
      "    - `zscores` (float): z‑score of the feature.\n",
      "    - `pos` (int): index into `lc_reb.t` / `lc_reb.c` for plotting.\n",
      "    - `t` (float): time coordinate for rate calculation.\n",
      "simdataset : pd.DataFrame\n",
      "    Detected features on a noise‑only (synthetic) light curve. Must contain `t`.\n",
      "lc_reb : object\n",
      "    Re-binned light curve object with attributes:\n",
      "    - `t` (array‑like): time stamps.\n",
      "    - `c` (array‑like): measured flux/rate.\n",
      "error_percentile_threshold : float, optional\n",
      "    Minimum error‑percentile (e.g. 0.9 means above the 90th percentile)\n",
      "    to keep a feature. Default is 0.9.\n",
      "zscore_threshold : float, optional\n",
      "    Minimum z‑score to keep a feature. Default is 4.\n",
      "show_plot : bool, optional\n",
      "    If True, overplot the filtered features on the light curve.\n",
      "    Default is True.\n",
      "\n",
      "\n",
      "Returns\n",
      "-------\n",
      "pd.DataFrame\n",
      "    Subset of `dataset` passing both thresholds, with index reset.\n",
      "\n",
      "Prints the probability of the dataset based on the rate (features/s) in the filtered light curve vs the rate of the filtered sysntetic light curve. \n",
      "\n",
      "## dipspeaks.dipspeaks_detection.analysis.gmm_dips_peaks\n",
      "\n",
      "Perform Gaussian Mixture Model (GMM) clustering on the provided data \n",
      "and compute cluster statistics.\n",
      "\n",
      "Parameters:\n",
      "- good_pd: DataFrame containing the data to cluster.\n",
      "- log_scale: Whether to apply logarithm transformation to the data.\n",
      "\n",
      "Returns:\n",
      "- cluster_stats_df: DataFrame containing the statistics for each cluster.\n",
      "- cluster_labels: Array of cluster labels for each data point. \n",
      "\n",
      "## dipspeaks.dipspeaks_detection.analysis.overlap\n",
      "\n",
      "Compute pairwise overlap durations and overlap ratios between two sets features (dips or peaks).\n",
      "Useful to analyze the behaviour of the dips/peaks and their presence in different energy ranges.\n",
      "    \n",
      "    Parameters\n",
      "----------\n",
      "high : pandas.DataFrame\n",
      "    DataFrame of “high-energy” features (peaks/dips). Must contain columns:\n",
      "    - **ti** : start time of each feature (array-like of shape (n_high,))\n",
      "    - **te** : end time of each feature (array-like of shape (n_high,))\n",
      "low : pandas.DataFrame\n",
      "    DataFrame of “low-energy” features. Must contain columns:\n",
      "    - **ti** : start time of each feature (array-like of shape (n_low,))\n",
      "    - **te** : end time of each feature (array-like of shape (n_low,))\n",
      "\n",
      "Returns\n",
      "-------\n",
      "overlap_durations : numpy.ndarray, shape (n_overlaps,)\n",
      "    Duration of each overlapping interval (zero-length overlaps dropped).\n",
      "high_indices : numpy.ndarray, shape (n_overlaps,)\n",
      "    Indices into `high` indicating which high-energy feature is involved.\n",
      "low_indices : numpy.ndarray, shape (n_overlaps,)\n",
      "    Indices into `low` indicating which low-energy feature is involved.\n",
      "high_overlap_ratio : numpy.ndarray, shape (n_overlaps,)\n",
      "    Overlap durations normalized by the duration of the corresponding high-energy feature:\n",
      "    $$\f",
      "rac{ ext{overlap}}{  ext{high.te} -  ext{high.ti}}.$$\n",
      "low_overlap_ratio : numpy.ndarray, shape (n_overlaps,)\n",
      "    Overlap durations normalized by the duration of the corresponding low-energy feature:\n",
      "    $$\f",
      "rac{ ext{overlap}}{  ext{low.te} -   ext{low.ti}}.$$ \n",
      "\n",
      "## dipspeaks.dipspeaks_detection.analysis.overlap_percentaje\n",
      "\n",
      "_(no docstring)_ \n",
      "\n",
      "## dipspeaks.dipspeaks_detection.dipspeaks_detection.detect_dips_and_peaks\n",
      "\n",
      "Detects dips and peaks in a given light curve using signal-to-noise ratio thresholding,\n",
      "synthetic data generation, and autoencoder-based anomaly detection.\n",
      "\n",
      "Parameters:\n",
      "-----------\n",
      "lc : str\n",
      "    File path to the input light curve (LC) data in text format.\n",
      "\n",
      "snr : float, optional (default=0.15)\n",
      "    The signal-to-noise ratio (SNR) threshold used to rebin the light curve data.\n",
      "\n",
      "index_time : int, optional (default=0)\n",
      "    Column index for time data in the LC file.\n",
      "\n",
      "index_rate : int, optional (default=1)\n",
      "    Column index for count rate data in the LC file.\n",
      "\n",
      "index_error_rate : int, optional (default=2)\n",
      "    Column index for error in count rate data in the LC file.\n",
      "\n",
      "num_simulations : int, optional (default=1)\n",
      "    Number of synthetic data simulations to generate for noise estimation and anomaly detection.\n",
      "\n",
      "show_plot : bool, optional (default=True)\n",
      "    Whether to display plots illustrating the detection process and results.\n",
      "\n",
      "Returns:\n",
      "--------\n",
      "peaks_to_clean : pandas.DataFrame\n",
      "    Detected peaks from the original LC data, along with calculated anomaly scores.\n",
      "\n",
      "dips_to_clean : pandas.DataFrame\n",
      "    Detected dips from the original LC data, along with calculated anomaly scores.\n",
      "\n",
      "lcreb : pandas.DataFrame\n",
      "    Rebinned LC data after applying the SNR threshold.\n",
      "\n",
      "speaks_to_clean : pandas.DataFrame\n",
      "    Detected peaks from the synthetic (simulated) LC data, for comparative analysis.\n",
      "\n",
      "sdips_to_clean : pandas.DataFrame\n",
      "    Detected dips from the synthetic (simulated) LC data, for comparative analysis. \n",
      "\n",
      "## dipspeaks.dipspeaks_detection.helper_functions.rebin_snr\n",
      "\n",
      "Rebin the signal based on the signal-to-noise ratio (SNR) threshold.\n",
      "\n",
      "Parameters:\n",
      "- t: Array of time values.\n",
      "- x: Array of signal values.\n",
      "- sy: Array of signal uncertainties (standard deviations).\n",
      "- snr_threshold: The SNR threshold for rebinned data.\n",
      "\n",
      "Returns:\n",
      "- t_new: Rebinned time values.\n",
      "- c_new: Rebinned signal values.\n",
      "- sc_new: Rebinned uncertainties. \n",
      "\n",
      "## dipspeaks.dipspeaks_detection.helper_functions.scale\n",
      "\n",
      "Scale the `x` data to match the range of the `y` data. The purpose is facilitate creation of plots.\n",
      "\n",
      "This function scales the values in the `x` array to match the range of the `y` array.\n",
      "It linearly transforms the `x` values such that they span the same range as `y`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "x : array-like\n",
      "    The input data to be scaled.\n",
      "y : array-like\n",
      "    The data whose range is used for scaling `x`.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "x_new : array-like\n",
      "    The scaled version of `x`, with values transformed to the range of `y`. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pkgutil\n",
    "import importlib\n",
    "import inspect\n",
    "\n",
    "def print_public_func_docs(package_name):\n",
    "    \"\"\"\n",
    "    Walks through all sub‐modules of `package_name`, finds public functions\n",
    "    (names not starting with “_”), and prints their fully qualified name\n",
    "    plus their docstring.\n",
    "    \"\"\"\n",
    "    pkg = importlib.import_module(package_name)\n",
    "    prefix = pkg.__name__ + \".\"\n",
    "\n",
    "    for finder, module_name, ispkg in pkgutil.walk_packages(pkg.__path__, prefix):\n",
    "        try:\n",
    "            module = importlib.import_module(module_name)\n",
    "        except ImportError:\n",
    "            continue  # skip modules that won’t import\n",
    "\n",
    "        for name, obj in inspect.getmembers(module, inspect.isfunction):\n",
    "            # only top‐level (module) functions, not imported from elsewhere:\n",
    "            if obj.__module__ == module_name and not name.startswith(\"_\"):\n",
    "                print(f\"## {module_name}.{name}\\n\")\n",
    "                doc = inspect.getdoc(obj) or \"_(no docstring)_\"\n",
    "                print(doc, \"\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print_public_func_docs(\"dipspeaks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b267fa8-518b-4277-aefa-67740b9d6392",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
